{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef230ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='你是一个AI助手,你的名字叫小智', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的问题是1 + 2 * 3 = ？', additional_kwargs={}, response_metadata={})]\n",
      "<class 'langchain_core.prompt_values.ChatPromptValue'>\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate(\n",
    "    messages = [(\"system\", \"你是一个AI助手,你的名字叫{name}\"), (\"human\", \"我的问题是{question}\")],\n",
    "    input_variables = [\"name\", \"question\"],\n",
    ")\n",
    "\n",
    "response = chat_prompt_template.invoke({\"name\":\"小智\",\"question\":\"1 + 2 * 3 = ？\"})\n",
    "print(response)\n",
    "print(type(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10e5fb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='你是一个AI助手,你的名字叫小智', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的问题是1 + 2 * 3 = ？', additional_kwargs={}, response_metadata={})]\n",
      "<class 'langchain_core.prompt_values.ChatPromptValue'>\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"你是一个AI助手,你的名字叫{name}\"), (\"human\", \"我的问题是{question}\")]\n",
    ")\n",
    "\n",
    "response = chat_prompt_template.invoke({\"name\":\"小智\",\"question\":\"1 + 2 * 3 = ？\"})\n",
    "print(response)\n",
    "print(type(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12437b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='你是一个AI助手,你的名字叫小智', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的问题是1 + 2 * 3 = ？', additional_kwargs={}, response_metadata={})]\n",
      "<class 'langchain_core.prompt_values.ChatPromptValue'>\n",
      "System: 你是一个AI助手,你的名字叫小智\n",
      "Human: 我的问题是1 +2 * 3 = ?\n",
      "<class 'str'>\n",
      "[SystemMessage(content='你是一个AI助手,你的名字叫小智', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的问题是1 +2 * 3 = ?', additional_kwargs={}, response_metadata={})]\n",
      "<class 'list'>\n",
      "messages=[SystemMessage(content='你是一个AI助手,你的名字叫小智', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的问题是1 +2 * 3 = ?', additional_kwargs={}, response_metadata={})]\n",
      "<class 'langchain_core.prompt_values.ChatPromptValue'>\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"你是一个AI助手,你的名字叫{name}\"), (\"human\", \"我的问题是{question}\")]\n",
    ")\n",
    "\n",
    "response = chat_prompt_template.invoke({\"name\":\"小智\",\"question\":\"1 + 2 * 3 = ？\"})\n",
    "print(response)\n",
    "print(type(response))\n",
    "\n",
    "response_1 = chat_prompt_template.format(name=\"小智\",question=\"1 +2 * 3 = ?\")\n",
    "print(response_1)\n",
    "print(type(response_1))\n",
    "\n",
    "response_2 = chat_prompt_template.format_messages(name=\"小智\",question=\"1 +2 * 3 = ?\")\n",
    "print(response_2)\n",
    "print(type(response_2))\n",
    "\n",
    "response_3 = chat_prompt_template.format_prompt(name=\"小智\",question=\"1 +2 * 3 = ?\")\n",
    "print(response_3)\n",
    "print(type(response_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b5810d",
   "metadata": {},
   "source": [
    "ChatPromptValue和list[messages]、str之间的转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13e80e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='你是一个AI助手,你的名字叫小智', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的问题是1 + 2 * 3 = ？', additional_kwargs={}, response_metadata={})]\n",
      "<class 'list'>\n",
      "System: 你是一个AI助手,你的名字叫小智\n",
      "Human: 我的问题是1 + 2 * 3 = ？\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"你是一个AI助手,你的名字叫{name}\"), (\"human\", \"我的问题是{question}\")]\n",
    ")\n",
    "\n",
    "response = chat_prompt_template.format_prompt(name=\"小智\",question=\"1 + 2 * 3 = ？\")\n",
    "\n",
    "response_messages = response.to_messages()\n",
    "print(response_messages)\n",
    "print(type(response_messages))\n",
    "\n",
    "response_str = response.to_string()\n",
    "print(response_str)\n",
    "print(type(response_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90016557",
   "metadata": {},
   "source": [
    "多种类型调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a09aeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[HumanMessage(content='我的问题是1 + 1 = ?', additional_kwargs={}, response_metadata={})]\n",
      "messages=[SystemMessage(content='你是一个人工智能领域专家,你叫小米', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的问题是介绍RAG', additional_kwargs={}, response_metadata={})]\n",
      "messages=[SystemMessage(content='我是一个人工智能助手,我的名字是{name}', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的问题是{question}', additional_kwargs={}, response_metadata={})]\n",
      "messages=[SystemMessage(content='你是一个专家小米', additional_kwargs={}, response_metadata={}), HumanMessage(content='解释介绍RAG,用浅显易懂的语言', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\"我的问题是{question}\"]\n",
    ")\n",
    "\n",
    "chat_prompt_template1 = ChatPromptTemplate.from_messages(\n",
    "    [{\"role\":\"system\", \"content\":\"你是一个人工智能领域专家,你叫{name}\"},\n",
    "     {\"role\":\"human\", \"content\":\"我的问题是{question}\"}]\n",
    ")\n",
    "\n",
    "chat_prompt_template2 = ChatPromptTemplate.from_messages(\n",
    "    [SystemMessage(content=\"我是一个人工智能助手,我的名字是{name}\"),\n",
    "     HumanMessage(content=\"我的问题是{question}\")]\n",
    ")\n",
    "\n",
    "system_template = \"你是一个专家{role}\"\n",
    "system_message_template = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "human_template = \"解释{concept},用浅显易懂的语言\"\n",
    "human_message_template = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt_template3 = ChatPromptTemplate.from_messages([\n",
    "    system_message_template, human_message_template\n",
    "])\n",
    "\n",
    "response = chat_prompt_template.invoke({\"question\":\"1 + 1 = ?\"})\n",
    "print(response)\n",
    "\n",
    "response_1 = chat_prompt_template1.invoke({\"name\":\"小米\",\"question\":\"介绍RAG\"})\n",
    "print(response_1)\n",
    "\n",
    "response_2 = chat_prompt_template2.invoke({\"name\":\"小米\",\"question\":\"介绍RAG\"})\n",
    "print(response_2)\n",
    "\n",
    "response_3 = chat_prompt_template3.invoke({\"role\":\"小米\",\"concept\":\"介绍RAG\"})\n",
    "print(response_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "734e832f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='当然可以！AIGC 是“人工智能生成内容”（Artificial Intelligence Generated Content）的缩写，指的是利用人工智能技术自动生成各种形式的内容。它是继专业生产内容（PGC）和用户生成内容（UGC）之后的一种新型内容创作方式。\\n\\n简单来说，AIGC 利用深度学习、自然语言处理、计算机视觉等AI技术，让机器能够“创作”出文字、图像、音频、视频、代码，甚至3D模型等内容。\\n\\n### AIGC 的主要应用领域包括：\\n\\n1. **文本生成**：如新闻写作、小说创作、邮件撰写、客服回复等，典型工具如 GPT 系列模型。\\n2. **图像生成**：根据文字描述生成图像，例如 MidJourney、Stable Diffusion、DALL·E 等。\\n3. **音频与语音合成**：生成逼真的语音、音乐创作，如AI配音、AI作曲。\\n4. **视频生成与编辑**：自动剪辑、生成短视频、虚拟主播等。\\n5. **代码生成**：帮助程序员自动生成代码，如 GitHub Copilot。\\n6. **多模态内容生成**：结合文本、图像、声音等多种模态生成更丰富的内容。\\n\\n### AIGC 的优势：\\n- 提高内容生产效率\\n- 降低创作门槛\\n- 实现个性化和规模化内容输出\\n\\n### 面临的挑战：\\n- 内容真实性与版权问题\\n- 伦理与滥用风险（如深度伪造）\\n- 质量控制与人工审核需求\\n\\n总的来说，AIGC 正在深刻改变内容产业的生态，被认为是未来数字内容创作的重要方向之一。随着大模型技术的不断进步，AIGC 的应用将更加广泛和深入。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 371, 'prompt_tokens': 25, 'total_tokens': 396, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-53058c8a-0824-4cfc-bbae-d70439655785', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--e83dc91c-6512-41b2-b4f3-8172e5531684-0' usage_metadata={'input_tokens': 25, 'output_tokens': 371, 'total_tokens': 396, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"DASHSCOPE_BASE_URL\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model = \"qwen-plus\"\n",
    ")\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    {\"role\": \"system\", \"content\":\"我是{domain}领域的专家\"},\n",
    "    {\"role\":\"human\", \"content\":\"我的问题是{question}\"}\n",
    "])\n",
    "\n",
    "prompt = prompt_template.invoke({\"domain\":\"人工智能领域\",\"question\":\"简单介绍AIGC\"})\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49d47ef",
   "metadata": {},
   "source": [
    "MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9da35158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='你是一个AI助手,你的名字叫小智', additional_kwargs={}, response_metadata={}), HumanMessage(content='我的问题是:1+1=?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"你是一个AI助手,你的名字叫{name}\"),\n",
    "    MessagesPlaceholder(variable_name = \"msgs\")\n",
    "])\n",
    "\n",
    "template = chat_prompt_template.invoke({\"name\":\"小智\",\"msgs\":[HumanMessage(content=\"我的问题是:1+1=?\")]})\n",
    "print(template)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
