{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87bd1dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€œ2ğŸš—9â€çœ‹èµ·æ¥åƒæ˜¯ä¸€ç§ç½‘ç»œç”¨è¯­æˆ–è¡¨æƒ…ç¬¦å·æ··åˆçš„è¡¨è¾¾æ–¹å¼ï¼Œå…¶ä¸­ï¼š\n",
      "\n",
      "- â€œ2â€ å¯èƒ½æ˜¯æ•°å­— 2ï¼Œ\n",
      "- â€œğŸš—â€ æ˜¯æ±½è½¦çš„è¡¨æƒ…ç¬¦å·ï¼ˆemojiï¼‰ï¼Œ\n",
      "- â€œ9â€ æ˜¯æ•°å­— 9ã€‚\n",
      "\n",
      "å¦‚æœä»å­—é¢ç†è§£ï¼Œè¿™å¯èƒ½ä¸æ˜¯ä¸€é“æ ‡å‡†æ•°å­¦é¢˜ã€‚ä¸è¿‡ï¼Œåœ¨ä¸­æ–‡ç½‘ç»œè¯­è¨€ä¸­ï¼Œæœ‰æ—¶ä¼šç”¨è°éŸ³æˆ–ç¬¦å·æ¥è¡¨è¾¾ç‰¹å®šå«ä¹‰ã€‚\n",
      "\n",
      "æˆ‘ä»¬æ¥åˆ†æå‡ ç§å¯èƒ½çš„è§£é‡Šï¼š\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **è°éŸ³æˆ–æ¢—çš„è¡¨è¾¾**\n",
      "åœ¨ä¸­æ–‡é‡Œï¼š\n",
      "- â€œ2â€ å¸¸ç”¨æ¥è¡¨ç¤ºâ€œäºŒâ€æˆ–â€œå‚»â€ï¼Œä¹Ÿå¯èƒ½æ˜¯â€œçˆ±â€çš„è°éŸ³ï¼ˆä½†è¾ƒå°‘è§ï¼‰ã€‚\n",
      "- â€œè½¦â€åœ¨ç½‘ç»œç”¨è¯­ä¸­ï¼Œæœ‰æ—¶æŒ‡â€œå¼€è½¦â€ï¼Œæ„æ€æ˜¯è®²é»„è‰²ç¬‘è¯æˆ–â€œå¼€é»„è…”â€ã€‚\n",
      "- â€œ9â€ è°éŸ³â€œä¹…â€ã€‚\n",
      "\n",
      "æ‰€ä»¥â€œ2ğŸš—9â€å¯èƒ½æ˜¯åœ¨å¼€ç©ç¬‘åœ°è¯´ï¼š\n",
      "> â€œçˆ±å¼€è½¦ï¼Œä¹…â€¦â€¦â€ æˆ– â€œäºŒè´§å¼€è½¦å»ä¹â€¦â€¦â€\n",
      "\n",
      "ä½†è¿™ä»ç„¶ä¸æ˜ç¡®ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### 2. **è¡¨æƒ…æ›¿ä»£è¿ç®—ç¬¦ï¼Ÿ**\n",
      "æœ‰äººå¯èƒ½ä¼šç”¨ emoji æ¥ä»£æ›¿è¿ç®—ç¬¦å·ã€‚ä¾‹å¦‚ï¼š\n",
      "- ğŸš— æ˜¯å¦ä»£è¡¨æŸç§è¿ç®—ï¼Ÿæ¯”å¦‚â€œåŠ â€ã€â€œå‡â€ï¼Ÿ\n",
      "  - ä½†æ²¡æœ‰æ™®éå…±è¯†è¯´ ğŸš— = + æˆ–å…¶ä»–ã€‚\n",
      "\n",
      "å¦‚æœå‡è®¾ ğŸš— æ˜¯â€œ+â€å·ï¼ˆå› ä¸ºè½¦åœ¨è·¯ä¸Šè·‘ï¼Œè¿æ¥ä¸¤åœ°ï¼Ÿçº¯çŒœæµ‹ï¼‰ï¼Œé‚£ä¹ˆï¼š\n",
      "> 2 ğŸš— 9 = 2 + 9 = **11**\n",
      "\n",
      "ä½†è¿™åªæ˜¯çŒœæµ‹ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### 3. **è½¦ç‰Œå·æˆ–æ¸¸æˆæœ¯è¯­ï¼Ÿ**\n",
      "åœ¨æŸäº›æ¸¸æˆä¸­ï¼Œâ€œ2è½¦9â€å¯èƒ½æœ‰ç‰¹æ®Šå«ä¹‰ï¼Œæ¯”å¦‚ï¼š\n",
      "- ç»„é˜Ÿæ—¶çš„ä½ç½®ç¼–å·ï¼Œ\n",
      "- æˆ–æŸç§æš—å·ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### 4. **æœ€å¯èƒ½çš„ç­”æ¡ˆï¼šç½‘ç»œç©ç¬‘ï¼Œæ— å®é™…æ•°å€¼**\n",
      "â€œ2ğŸš—9â€å¾ˆå¯èƒ½æ˜¯ä¸€ä¸ª**ç½‘ç»œæ¢—**æˆ–**æç¬‘è¡¨è¾¾**ï¼Œå¹¶ä¸çœŸçš„ç­‰äºæŸä¸ªæ•°ã€‚å®ƒå¯èƒ½æºè‡ªï¼š\n",
      "- æŸä¸ªçŸ­è§†é¢‘ã€ç›´æ’­ä¸­çš„å£è¯¯æˆ–æ¢—ï¼Œ\n",
      "- æˆ–æ¨¡ä»¿â€œæ•°å­¦é¢˜â€çš„å½¢å¼æ¥æç¬‘ï¼Œæ¯”å¦‚â€œ1+1=ğŸ·â€è¿™ç±»åé€»è¾‘è¡¨è¾¾ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### ç»“è®ºï¼š\n",
      "å¦‚æœæ²¡æœ‰ä¸Šä¸‹æ–‡ï¼Œâ€œ2ğŸš—9â€**ä¸æ˜¯ä¸€ä¸ªæ ‡å‡†æ•°å­¦è¡¨è¾¾å¼**ï¼Œæ— æ³•å¾—å‡ºç¡®åˆ‡æ•°å€¼ã€‚\n",
      "\n",
      "ä½†å¦‚æœå¼ºè¡Œè§£è¯»ï¼Œä¸”å‡è®¾ ğŸš— = +ï¼Œé‚£ä¹ˆï¼š\n",
      "> 2 ğŸš— 9 = 2 + 9 = **11**\n",
      "\n",
      "âœ… æ‰€ä»¥ï¼Œä¸€ä¸ªåˆç†çš„å¹½é»˜å›ç­”æ˜¯ï¼š**11**ï¼ˆå‰ææ˜¯â€œè½¦â€ä»£è¡¨â€œåŠ â€ï¼‰\n",
      "\n",
      "æˆ–è€…æ›´æœ‰è¶£åœ°å›ç­”ï¼š\n",
      "> â€œ2ğŸš—9 = ä¸€èµ·å¼€è½¦å»å…œé£~â€ ğŸ˜\n",
      "\n",
      "---\n",
      "\n",
      "å¦‚æœä½ èƒ½æä¾›è¿™ä¸ªè¡¨è¾¾çš„æ¥æºæˆ–ä¸Šä¸‹æ–‡ï¼ˆæ¯”å¦‚æ˜¯æŸä¸ªè§†é¢‘ã€ç¾¤èŠæ¢—ã€æ¸¸æˆæœ¯è¯­ï¼‰ï¼Œæˆ‘å¯ä»¥ç»™å‡ºæ›´å‡†ç¡®çš„è§£é‡Šï¼\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"DASHSCOPE_BASE_URL\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model = \"qwen-plus\"\n",
    ")\n",
    "\n",
    "res = llm.invoke(\"2ğŸš—9æ˜¯å¤šå°‘?\")\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a283c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='å¤©æ´¥å¸‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 47, 'total_tokens': 48, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-8cb869c6-198b-49a6-b20d-c229ec85f058', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--15c6eb7f-a46e-4bee-ac7f-c569139737ab-0', usage_metadata={'input_tokens': 47, 'output_tokens': 1, 'total_tokens': 48, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate,FewShotPromptTemplate\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"DASHSCOPE_BASE_URL\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model = \"qwen-plus\"\n",
    ")\n",
    "\n",
    "#æç¤ºè¯æ¨¡æ¿\n",
    "example_prompt = PromptTemplate.from_template(\n",
    "    template=\"Input:{input}\\nOutput:{output}\"\n",
    ")\n",
    "\n",
    "#æä¾›ç¤ºä¾‹\n",
    "examples = [\n",
    "    {\"input\": \"åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·\", \"output\": \"åŒ—äº¬å¸‚\"},\n",
    "    {\"input\": \"å—äº¬ä¸‹é›¨å—\", \"output\": \"å—äº¬å¸‚\"},\n",
    "    {\"input\": \"æ­¦æ±‰çƒ­å—\", \"output\": \"æ­¦æ±‰å¸‚\"}]\n",
    "\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    example_prompt= example_prompt,\n",
    "    examples = examples,\n",
    "    suffix= \"input:{input}\\noutput:\",\n",
    "    input_variables=[\"input\"],\n",
    "    )\n",
    "\n",
    "llm.invoke(few_shot_prompt_template.invoke({\"input\":\"å¤©æ´¥ä¼šä¸‹é›¨å—?\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b453ea02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 1+1ç­‰äºå‡ ?\n",
      "AI: 1+1ç­‰äº2\n",
      "Human: æ³•å›½çš„é¦–éƒ½æ˜¯?\n",
      "AI: å·´é»\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import FewShotChatMessagePromptTemplate, ChatPromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\"input\":\"1+1ç­‰äºå‡ ?\",\"output\":\"1+1ç­‰äº2\"},\n",
    "    {\"input\":\"æ³•å›½çš„é¦–éƒ½æ˜¯?\",\"output\":\"å·´é»\"}\n",
    "]\n",
    "\n",
    "msg_example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\",\"{input}\"),\n",
    "    (\"ai\",\"{output}\"),\n",
    "])\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=msg_example_prompt,\n",
    "    examples = examples\n",
    "    )\n",
    "\n",
    "print(few_shot_prompt.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8243f778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'16\\n\\nçœ‹èµ·æ¥ä½ å®šä¹‰çš„è¿ç®— â€œğŸš—â€ æ˜¯ï¼š  \\n**a ğŸš— b = a çš„ b æ¬¡æ–¹**ï¼Œä¹Ÿå°±æ˜¯ $ a^b $ã€‚\\n\\néªŒè¯ä¸€ä¸‹ï¼š\\n- 2 ğŸš— 2 = $ 2^2 = 4 $\\n- 2 ğŸš— 3 = $ 2^3 = 8 $\\n- 2 ğŸš— 4 = $ 2^4 = 16 $\\n\\næ‰€ä»¥ç­”æ¡ˆæ˜¯ï¼š**16** âœ…\\n\\nç»§ç»­æŒ‘æˆ˜å—ï¼Ÿæ¯”å¦‚ 3 ğŸš— 3 æ˜¯å¤šå°‘ï¼ŸğŸ˜„'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import FewShotChatMessagePromptTemplate, ChatPromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\"input\":\"2ğŸš—2\",\"output\":\"4\"},\n",
    "    {\"input\":\"2ğŸš—3\",\"output\":\"8\"},\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('human','{input}æ˜¯å¤šå°‘?'),\n",
    "    ('ai','{output}')\n",
    "])\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [('system','ä½ æ˜¯ä¸€ä¸ªæ•°å­¦å¥‡æ‰'),\n",
    "     few_shot_prompt,\n",
    "     ('human','{input}')]\n",
    ")\n",
    "\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('DASHSCOPE_API_KEY')\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"DASHSCOPE_BASE_URL\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model = 'qwen-plus'\n",
    ")\n",
    "\n",
    "llm.invoke(final_prompt.invoke(input=\"2ğŸš—4\")).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "451d9d77",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'message': 'The model `Qwen3-Embedding-4B` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}, 'request_id': '3abb16bd-1c02-47fb-8083-f5d83b1a9623'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFoundError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     12\u001b[39m embedding_model = OpenAIEmbeddings(\n\u001b[32m     13\u001b[39m     model = \u001b[33m\"\u001b[39m\u001b[33mQwen3-Embedding-4B\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     14\u001b[39m )\n\u001b[32m     16\u001b[39m examples = [\n\u001b[32m     17\u001b[39m     { \n\u001b[32m     18\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mè°æ´»å¾—æ›´ä¹…ï¼Œç©†ç½•é»˜å¾·Â·é˜¿é‡Œè¿˜æ˜¯è‰¾ä¼¦Â·å›¾çµ?\u001b[39m\u001b[33m\"\u001b[39m,        \n\u001b[32m   (...)\u001b[39m\u001b[32m     48\u001b[39m     },\n\u001b[32m     49\u001b[39m  ]\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m example_selector = \u001b[43mSemanticSimilarityExampleSelector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_examples\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43mChroma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m question=\u001b[33m\"\u001b[39m\u001b[33mç›ä¸½Â·é²å°”Â·åç››é¡¿çš„çˆ¶äº²æ˜¯è°?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     59\u001b[39m selected_examples = example_selector.select_examples({\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m:question})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm/lib/python3.13/site-packages/langchain_core/example_selectors/semantic_similarity.py:171\u001b[39m, in \u001b[36mSemanticSimilarityExampleSelector.from_examples\u001b[39m\u001b[34m(cls, examples, embeddings, vectorstore_cls, k, input_keys, example_keys, vectorstore_kwargs, **vectorstore_cls_kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create k-shot example selector using example list and embeddings.\u001b[39;00m\n\u001b[32m    152\u001b[39m \n\u001b[32m    153\u001b[39m \u001b[33;03mReshuffles examples dynamically based on query similarity.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    168\u001b[39m \u001b[33;03m    The ExampleSelector instantiated, backed by a vector store.\u001b[39;00m\n\u001b[32m    169\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    170\u001b[39m string_examples = [\u001b[38;5;28mcls\u001b[39m._example_to_text(eg, input_keys) \u001b[38;5;28;01mfor\u001b[39;00m eg \u001b[38;5;129;01min\u001b[39;00m examples]\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m vectorstore = \u001b[43mvectorstore_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstring_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mvectorstore_cls_kwargs\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[32m    175\u001b[39m     vectorstore=vectorstore,\n\u001b[32m    176\u001b[39m     k=k,\n\u001b[32m   (...)\u001b[39m\u001b[32m    179\u001b[39m     vectorstore_kwargs=vectorstore_kwargs,\n\u001b[32m    180\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm/lib/python3.13/site-packages/langchain_community/vectorstores/chroma.py:843\u001b[39m, in \u001b[36mChroma.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[39m\n\u001b[32m    835\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbatch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[32m    837\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[32m    838\u001b[39m         api=chroma_collection._client,\n\u001b[32m    839\u001b[39m         ids=ids,\n\u001b[32m    840\u001b[39m         metadatas=metadatas,\n\u001b[32m    841\u001b[39m         documents=texts,\n\u001b[32m    842\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m         \u001b[43mchroma_collection\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    849\u001b[39m     chroma_collection.add_texts(texts=texts, metadatas=metadatas, ids=ids)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm/lib/python3.13/site-packages/langchain_community/vectorstores/chroma.py:277\u001b[39m, in \u001b[36mChroma.add_texts\u001b[39m\u001b[34m(self, texts, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m texts = \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embedding_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[32m    279\u001b[39m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[32m    280\u001b[39m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[32m    281\u001b[39m     length_diff = \u001b[38;5;28mlen\u001b[39m(texts) - \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm/lib/python3.13/site-packages/langchain_openai/embeddings/base.py:592\u001b[39m, in \u001b[36mOpenAIEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts, chunk_size, **kwargs)\u001b[39m\n\u001b[32m    589\u001b[39m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[32m    590\u001b[39m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[32m    591\u001b[39m engine = cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m.deployment)\n\u001b[32m--> \u001b[39m\u001b[32m592\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm/lib/python3.13/site-packages/langchain_openai/embeddings/base.py:482\u001b[39m, in \u001b[36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[39m\u001b[34m(self, texts, engine, chunk_size, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m batched_embeddings: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]] = []\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[32m--> \u001b[39m\u001b[32m482\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mclient_kwargs\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    485\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    486\u001b[39m         response = response.model_dump()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm/lib/python3.13/site-packages/openai/resources/embeddings.py:132\u001b[39m, in \u001b[36mEmbeddings.create\u001b[39m\u001b[34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m             embedding.embedding = np.frombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m    127\u001b[39m                 base64.b64decode(data), dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    128\u001b[39m             ).tolist()\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm/lib/python3.13/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm/lib/python3.13/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNotFoundError\u001b[39m: Error code: 404 - {'error': {'message': 'The model `Qwen3-Embedding-4B` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}, 'request_id': '3abb16bd-1c02-47fb-8083-f5d83b1a9623'}"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "os.environ['OPENAI_BASR_URL'] = os.getenv(\"DASHSCOPE_BASE_URL\")\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(\n",
    "    model = \"Qwen3-Embedding-4B\"\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    { \n",
    "        \"question\": \"è°æ´»å¾—æ›´ä¹…ï¼Œç©†ç½•é»˜å¾·Â·é˜¿é‡Œè¿˜æ˜¯è‰¾ä¼¦Â·å›¾çµ?\",        \n",
    "        \"answer\": \"\"\"\n",
    "            æ¥ä¸‹æ¥è¿˜éœ€è¦é—®ä»€ä¹ˆé—®é¢˜å—ï¼Ÿ\n",
    "            è¿½é—®ï¼šç©†ç½•é»˜å¾·Â·é˜¿é‡Œå»ä¸–æ—¶å¤šå¤§å¹´çºªï¼Ÿ\n",
    "            ä¸­é—´ç­”æ¡ˆï¼šç©†ç½•é»˜å¾·Â·é˜¿é‡Œå»ä¸–æ—¶äº«å¹´74å²ã€‚\n",
    "            \"\"\",\n",
    "    },\n",
    "    {      \n",
    "        \"question\": \"craigslistçš„åˆ›å§‹äººæ˜¯ä»€ä¹ˆæ—¶å€™å‡ºç”Ÿçš„ï¼Ÿ\",\n",
    "        \"answer\": \"\"\"\n",
    "            æ¥ä¸‹æ¥è¿˜éœ€è¦é—®ä»€ä¹ˆé—®é¢˜å—ï¼Ÿ\n",
    "            è¿½é—®ï¼šè°æ˜¯craigslistçš„åˆ›å§‹äººï¼Ÿ\n",
    "            ä¸­çº§ç­”æ¡ˆï¼šCraigslistæ˜¯ç”±å…‹é›·æ ¼Â·çº½é©¬å…‹åˆ›ç«‹çš„ã€‚\n",
    "        \"\"\",\n",
    "    },\n",
    "    {   \n",
    "        \"question\": \"è°æ˜¯ä¹”æ²»Â·åç››é¡¿çš„å¤–ç¥–çˆ¶ï¼Ÿ\", \n",
    "        \"answer\":\"\"\"\n",
    "            æ¥ä¸‹æ¥è¿˜éœ€è¦é—®ä»€ä¹ˆé—®é¢˜å—ï¼Ÿ\n",
    "            è¿½é—®ï¼šè°æ˜¯ä¹”æ²»Â·åç››é¡¿çš„æ¯äº²ï¼Ÿ\n",
    "            ä¸­é—´ç­”æ¡ˆï¼šä¹”æ²»Â·åç››é¡¿çš„æ¯äº²æ˜¯ç›ä¸½Â·é²å°”Â·åç››é¡¿ã€‚\n",
    "        \"\"\",\n",
    "    },\n",
    "    { \n",
    "        \"question\": \"ã€Šå¤§ç™½é²¨ã€‹å’Œã€Šçš‡å®¶èµŒåœºã€‹çš„å¯¼æ¼”éƒ½æ¥è‡ªåŒä¸€ä¸ªå›½å®¶å—ï¼Ÿ\",\n",
    "        \"answer\": \"\"\"\n",
    "            æ¥ä¸‹æ¥è¿˜éœ€è¦é—®ä»€ä¹ˆé—®é¢˜å—ï¼Ÿ\n",
    "            è¿½é—®ï¼šã€Šå¤§ç™½é²¨ã€‹çš„å¯¼æ¼”æ˜¯è°ï¼Ÿ\n",
    "            ä¸­çº§ç­”æ¡ˆï¼šã€Šå¤§ç™½é²¨ã€‹çš„å¯¼æ¼”æ˜¯å²è’‚æ–‡Â·æ–¯çš®å°”ä¼¯æ ¼ã€‚\n",
    "        \"\"\",\n",
    "    },\n",
    " ]\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples,\n",
    "    embedding_model,\n",
    "    Chroma,\n",
    "    k = 1,\n",
    ")\n",
    "\n",
    "question=\"ç›ä¸½Â·é²å°”Â·åç››é¡¿çš„çˆ¶äº²æ˜¯è°?\"\n",
    "selected_examples = example_selector.select_examples({\"question\":question})\n",
    "print(f\"ä¸è¾“å…¥æœ€ç›¸ä¼¼çš„ç¤ºä¾‹ï¼š{selected_examples}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
