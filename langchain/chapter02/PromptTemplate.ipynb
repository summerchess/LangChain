{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b01e591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['topic'] input_types={} partial_variables={} template='è¯·ç®€è¦æè¿°{topic}çš„åº”ç”¨.'\n",
      "æç¤ºè¯1: è¯·ç®€è¦æè¿°æœºå™¨å­¦ä¹ çš„åº”ç”¨.\n",
      "æç¤ºè¯2: è¯·ç®€è¦æè¿°è‡ªç„¶è¯­è¨€å¤„ç†çš„åº”ç”¨.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate(template=\"è¯·ç®€è¦æè¿°{topic}çš„åº”ç”¨.\", \n",
    "                          input_variables=[\"topic\"])\n",
    "\n",
    "print(template)\n",
    "\n",
    "prompt_1 = template.format(topic=\"æœºå™¨å­¦ä¹ \")\n",
    "prompt_2 = template.format(topic=\"è‡ªç„¶è¯­è¨€å¤„ç†\")\n",
    "\n",
    "print(\"æç¤ºè¯1:\", prompt_1)\n",
    "print(\"æç¤ºè¯2:\", prompt_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cf6395",
   "metadata": {},
   "source": [
    "#å¤šå˜é‡æ¨¡æ¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e5df6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æç¤ºè¯1: è¯·è¯„ä»·æ™ºèƒ½æ‰‹æœºçš„ä¼˜ç¼ºç‚¹,åŒ…æ‹¬ç”µæ± ç»­èˆªå’Œæ‹ç…§è´¨é‡\n",
      "æç¤ºè¯2: è¯·è¯„ä»·ç¬”è®°æœ¬ç”µè„‘çš„ä¼˜ç¼ºç‚¹,åŒ…æ‹¬å¤„ç†é€Ÿåº¦å’Œä¾¿æºæ€§\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate(\n",
    "    template=\"è¯·è¯„ä»·{product}çš„ä¼˜ç¼ºç‚¹,åŒ…æ‹¬{aspect1}å’Œ{aspect2}\",\n",
    "    input_variables=[\"product\", \"aspect1\", \"aspect2\"]\n",
    ")\n",
    "\n",
    "prompt_1 = template.format(product=\"æ™ºèƒ½æ‰‹æœº\",aspect1=\"ç”µæ± ç»­èˆª\",aspect2=\"æ‹ç…§è´¨é‡\")\n",
    "prompt_2 = template.format(product=\"ç¬”è®°æœ¬ç”µè„‘\",aspect1=\"å¤„ç†é€Ÿåº¦\",aspect2=\"ä¾¿æºæ€§\")\n",
    "\n",
    "print(\"æç¤ºè¯1:\",prompt_1)\n",
    "print(\"æç¤ºè¯2:\",prompt_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a77873e",
   "metadata": {},
   "source": [
    "from_template  #æ¨è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dc00a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['topic'] input_types={} partial_variables={} template='è¯·ç®€è¦æè¿°{topic}çš„åº”ç”¨.'\n",
      "æç¤ºè¯1: è¯·ç®€è¦æè¿°æœºå™¨å­¦ä¹ çš„åº”ç”¨.\n",
      "æç¤ºè¯2: è¯·ç®€è¦æè¿°è‡ªç„¶è¯­è¨€å¤„ç†çš„åº”ç”¨.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate.from_template(template=\"è¯·ç®€è¦æè¿°{topic}çš„åº”ç”¨.\")\n",
    "\n",
    "print(template)\n",
    "\n",
    "prompt_1 = template.format(topic=\"æœºå™¨å­¦ä¹ \")\n",
    "prompt_2 = template.format(topic=\"è‡ªç„¶è¯­è¨€å¤„ç†\")\n",
    "\n",
    "print(\"æç¤ºè¯1:\", prompt_1)\n",
    "print(\"æç¤ºè¯2:\", prompt_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3061afe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me a joke\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "text = \"\"\"Tell me a joke\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(text)\n",
    "\n",
    "prompt = prompt_template.format()\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11acf52",
   "metadata": {},
   "source": [
    "éƒ¨åˆ†æç¤ºè¯æ¨¡æ¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39eb5a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¯·è¯„ä»·æ™ºèƒ½æ‰‹æœºçš„ä¼˜ç¼ºç‚¹,åŒ…æ‹¬ç”µæ± ç»­èˆªå’Œæ‹ç…§è´¨é‡\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate.from_template(\n",
    "    template=\"è¯·è¯„ä»·{product}çš„ä¼˜ç¼ºç‚¹,åŒ…æ‹¬{aspect1}å’Œ{aspect2}\",\n",
    "    partial_variables={\"aspect1\":\"ç”µæ± ç»­èˆª\"}\n",
    ")\n",
    "\n",
    "prompt_1 = template.format(product=\"æ™ºèƒ½æ‰‹æœº\",aspect2=\"æ‹ç…§è´¨é‡\")\n",
    "print(prompt_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d681d91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¯·è¯„ä»·æ™ºèƒ½æ‰‹æœºçš„ä¼˜ç¼ºç‚¹,åŒ…æ‹¬ç”µæ± ç»­èˆªå’Œæ‹ç…§è´¨é‡\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate.from_template(\n",
    "    template=\"è¯·è¯„ä»·{product}çš„ä¼˜ç¼ºç‚¹,åŒ…æ‹¬{aspect1}å’Œ{aspect2}\"\n",
    ").partial (aspect1=\"ç”µæ± ç»­èˆª\",aspect2=\"æ‹ç…§è´¨é‡\")\n",
    "\n",
    "prompt = template.format(product=\"æ™ºèƒ½æ‰‹æœº\",aspect2=\"æ‹ç…§è´¨é‡\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c680fe",
   "metadata": {},
   "source": [
    "ç»„åˆæç¤ºè¯çš„ä½¿ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9eaded6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me a joke about sports, make it funny\n",
      "\n",
      "and in spanish\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = (\n",
    "    PromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "                                 + \", make it funny\"\n",
    "                                 + \"\\n\\nand in {language}\")\n",
    "prompt = template.format(topic = \"sports\", language=\"spanish\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b23280c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='Tell me a funny joke about chickens.'\n",
      "<class 'langchain_core.prompt_values.StringPromptValue'>\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} joke about {content}.\"\n",
    ")\n",
    "\n",
    "prompt = prompt_template.invoke({\"adjective\": \"funny\", \"content\": \"chickens\"})\n",
    "print(prompt)\n",
    "print(type(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3f04f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Why did the chicken get promoted?\\n\\nBecause it was outstanding in its field! ğŸ”ğŸ˜„' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 16, 'total_tokens': 35, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-a8e1436e-f61a-41ee-993b-599367b7f1a8', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--d9fefcd3-6e0c-4dda-adf4-21f947f56d6e-0' usage_metadata={'input_tokens': 16, 'output_tokens': 19, 'total_tokens': 35, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"DASHSCOPE_BASE_URL\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model = 'qwen-plus'\n",
    ")\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} joke about {content}.\"\n",
    ")\n",
    "\n",
    "prompt = prompt_template.invoke({\"adjective\": \"funny\", \"content\": \"chickens\"})\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
