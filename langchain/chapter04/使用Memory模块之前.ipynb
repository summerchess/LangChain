{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a0cc93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ¨¡å‹å›ç­”:Hello! It looks like you have a question. Could you please provide more details or clarify what you'd like to ask? I'm here to help! ğŸ˜Š\n",
      "æ¨¡å‹å›ç­”:è¿™æ˜¯ä¸€ä¸ªéå¸¸æœ‰è¶£çš„é—®é¢˜ï¼\n",
      "\n",
      "å…¶å®ï¼Œ**å­”å­å¹¶ä¸å§“â€œå­”â€**ã€‚\n",
      "\n",
      "æˆ‘ä»¬é€šå¸¸è¯´â€œå­”å­â€ï¼Œè¿™é‡Œçš„â€œå­â€æ˜¯å¤ä»£å¯¹æœ‰å­¦é—®ã€æœ‰å¾·è¡Œçš„äººçš„å°Šç§°ï¼ˆæ¯”å¦‚â€œè€å­â€â€œå­Ÿå­â€ï¼‰ï¼Œè€Œâ€œå­”â€å…¶å®æ˜¯ä»–çš„**æ°**ï¼Œä¸æ˜¯ä»–çš„**å§“**ã€‚\n",
      "\n",
      "è¦å¼„æ¸…æ¥šè¿™ä¸ªé—®é¢˜ï¼Œå¾—ä»å…ˆç§¦æ—¶æœŸçš„å§“æ°åˆ¶åº¦è¯´èµ·ï¼š\n",
      "\n",
      "### 1. å§“ä¸æ°çš„åŒºåˆ«\n",
      "åœ¨æ˜¥ç§‹æˆ˜å›½æ—¶æœŸï¼Œâ€œå§“â€å’Œâ€œæ°â€æ˜¯åˆ†å¼€çš„ï¼š\n",
      "- **å§“**ï¼šä»£è¡¨è¡€ç¼˜èµ·æºï¼Œé€šå¸¸æ¥è‡ªæ¯ç³»ï¼Œæ¯”è¾ƒç¨³å®šï¼Œä¸–ä»£ç›¸ä¼ ã€‚\n",
      "- **æ°**ï¼šæ˜¯å§“çš„åˆ†æ”¯ï¼Œç”¨æ¥åŒºåˆ†å®¶æ—ã€å°åœ°ã€å®˜èŒç­‰ï¼Œå¯ä»¥å˜åŒ–ã€‚\n",
      "\n",
      "### 2. å­”å­çš„çœŸå®å§“æ°\n",
      "å­”å­çš„ç¥–å…ˆæ˜¯å®‹å›½çš„è´µæ—ï¼Œæºè‡ªå•†æœç‹å®¤ã€‚ä»–çš„ç¥–å…ˆ**å¾®å­å¯**æ˜¯å•†çº£ç‹çš„å…„å¼Ÿï¼Œå±äº**å­å§“**ã€‚\n",
      "\n",
      "åæ¥ï¼Œå­”å­çš„å…­ä¸–ç¥–**å­”çˆ¶å˜‰**ï¼ˆåå˜‰ï¼Œå­—å­”çˆ¶ï¼‰åœ¨å®‹å›½åšå®˜ã€‚â€œå­”çˆ¶â€æ˜¯å­—ï¼Œä»–çš„åä»£å°±ä»¥â€œå­”â€ä¸º**æ°**ï¼Œä»¥ç¤ºçºªå¿µã€‚\n",
      "\n",
      "æ‰€ä»¥ï¼Œä»å­”çˆ¶å˜‰å¼€å§‹ï¼Œè¿™ä¸€æ”¯åäººå°±ä»¥â€œå­”â€ä¸ºæ°ï¼Œä½†ä»ç„¶ä¿ç•™åŸæ¥çš„â€œ**å­**â€å§“ã€‚\n",
      "\n",
      "### âœ… ç»“è®ºï¼š\n",
      "- **å­”å­å§“â€œå­â€**ï¼ˆæ²¡é”™ï¼Œå’Œâ€œå­©å­â€çš„â€œå­â€åŒå­—ï¼‰\n",
      "- **æ°â€œå­”â€**\n",
      "- åâ€œä¸˜â€ï¼Œå­—â€œä»²å°¼â€\n",
      "\n",
      "æ‰€ä»¥æˆ‘ä»¬ç§°å‘¼ä»–ä¸ºâ€œå­”å­â€ï¼Œå…¶å®æ˜¯â€œå­”æ°ä¹‹å­â€çš„æ„æ€ï¼Œæ˜¯ä¸€ç§å°Šç§°ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "ğŸ“Œ ç±»ä¼¼ä¾‹å­ï¼š\n",
      "- å±ˆåŸï¼šå§“â€œèŠˆâ€ï¼Œæ°â€œå±ˆâ€ï¼Œåâ€œå¹³â€ï¼Œå­—â€œåŸâ€\n",
      "- ç§¦å§‹çš‡ï¼šå§“â€œå¬´â€ï¼Œæ°â€œèµµâ€ï¼ˆæˆ–ç§°èµµæ”¿ï¼‰ï¼Œåâ€œæ”¿â€\n",
      "\n",
      "éšç€å†å²å‘å±•ï¼Œå§“æ°é€æ¸åˆä¸€ï¼Œåˆ°äº†æ±‰ä»£ä»¥åï¼Œâ€œå§“æ°â€å°±åˆåœ¨ä¸€èµ·äº†ï¼Œä¸å†åŒºåˆ†ã€‚\n",
      "\n",
      "ğŸ˜Š æ‰€ä»¥ç­”æ¡ˆæ˜¯ï¼š**å­”å­ä¸å§“å­”ï¼Œä»–å§“å­ï¼Œæ°å­”ã€‚**\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage,HumanMessage,AIMessage\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"DASHSCOPE_BASE_URL\")\n",
    "\n",
    "chat_model = ChatOpenAI(model = 'qwen-plus')\n",
    "\n",
    "def chat_with_model(answer):\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\"ä½ æ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½çš„åŠ©æ‰‹\"),\n",
    "        (\"human\",\"question\")\n",
    "    ])\n",
    "\n",
    "    while True:\n",
    "        chain = prompt_template | chat_model\n",
    "        response = chain.invoke({\"question\":answer})\n",
    "\n",
    "        print(f\"æ¨¡å‹å›ç­”:{response.content}\")\n",
    "\n",
    "        user_input = input(\"ä½ è¿˜æœ‰å…¶ä»–é—®é¢˜å—ï¼Ÿï¼ˆè¾“å…¥é€€å‡ºæ—¶ï¼Œç»“æŸä¼šè¯ï¼‰\")\n",
    "\n",
    "        if(user_input == \"é€€å‡º\"):\n",
    "            break\n",
    "\n",
    "        prompt_template.messages.append(AIMessage(content=response.content))\n",
    "        prompt_template.messages.append(HumanMessage(content=user_input))\n",
    "\n",
    "chat_with_model(\"ä½ å¥½ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e149af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    x = x - np.max(x,axis=-1,keepdims=True)\n",
    "    exp_x = np.exp(x)\n",
    "    return exp_x / np.sum(exp_x,axis=-1,keepdims=True)\n",
    "\n",
    "def scaled_dot_product_attention(Q,K,V):\n",
    "    d_k = Q.shape[-1]\n",
    "    scores = Q @ K.T / np.sqrt(d_k)\n",
    "    weights = softmax(scores)\n",
    "    return weights @ V\n",
    "\n",
    "def mha(X,num_heads=2):\n",
    "    n, d_model = X.shape\n",
    "    assert d_model % num_heads == 0\n",
    "    d_k = d_v = d_model // num_heads\n",
    "\n",
    "    W_Q = np.random.randn(num_heads,d_model,d_k)\n",
    "    W_K = np.random.randn(num_heads,d_model,d_k)\n",
    "    W_V = np.random.randn(num_heads,d_model,d_v)\n",
    "    W_O = np.random.randn(num_heads * d_v, d_model)\n",
    "    \n",
    "    heads = []\n",
    "    for i in range(num_heads):\n",
    "        Q = X @ W_Q[i]\n",
    "        K = X @ W_K[i]\n",
    "        V = X @ W_V[i]\n",
    "\n",
    "        head = scaled_dot_product_attention(Q,K,V)\n",
    "        heads.append(head)\n",
    "    \n",
    "    concat = np.concatenate(heads,axis=-1)\n",
    "    output = concat @ W_O\n",
    "    return output\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
